<<app.py>> <<code>> from fastapi import FastAPI, UploadFile, File, Form,APIRouter from fastapi.responses import JSONResponse from cleanup import cleanup_old_files from langchain.chains.summarize import load_summarize_chain from typing import List,Literal import uvicorn import shutil import os from sm_chain import CustomLLM from utils import extract_text_from_pdf, get_diff_context,load_and_chunk_pdf app = FastAPI() router = APIRouter() UPLOAD_DIR = "uploads" os.makedirs(UPLOAD_DIR, exist_ok=True) version_pairs = [] version_summaries = [] def save_file(file: UploadFile) -> str: file_path = os.path.join(UPLOAD_DIR, file.filename) with open(file_path, "wb") as f: shutil.copyfileobj(file.file, f) return file_path @router.post("/process/") async def process(mode: Literal["summarize", "difference"] = Form(...), files: List[UploadFile] = File(...)): cleanup_old_files() if mode == "summarize": if len(files) != 1: return JSONResponse(status_code=400, content={"error": "Upload exactly 1 file for summarize mode."}) file_path = save_file(files[0]) chunks = load_and_chunk_pdf(file_path) try: text= extract_text_from_pdf(file_path) summary = CustomLLM()(text,mode = 'summarize') return {"summary": summary} except Exception as e: summaries = [CustomLLM()(doc.page_content,mode = 'summarize') for doc in chunks] combined = '\n\n'.join(summaries) summary = CustomLLM()(combined,mode="summarize") return {"summary": summary} # return JSONResponse(status_code=500, content={"error": f"LLM processing failed: {str(e)}"}) elif mode == "difference": if len(files) != 2: return JSONResponse(status_code=400, content={"error": "Upload exactly 2 files for difference mode."}) file1_path = save_file(files[0]) file2_path = save_file(files[1]) name1, name2 = files[0].filename, files[1].filename text1 = extract_text_from_pdf(file1_path) text2 = extract_text_from_pdf(file2_path) diff_text = get_diff_context(text1, text2) summary = CustomLLM()(diff_text,mode ="difference") version_pairs.append((name1, name2)) version_summaries.append(summary) return { "from_version": name1, "to_version": name2, "diff_summary": summary } else: return JSONResponse(status_code=400, content={"error": "Invalid mode. Choose 'summarize' or 'difference'."}) @router.post("/extract_fields/") async def extract_fields(files: List[UploadFile] = File(...)): cleanup_old_files() if len(files) != 1: return JSONResponse(status_code=400, content={"error": "Upload exactly 1 file to extract fields."}) file_path = save_file(files[0]) chunks = load_and_chunk_pdf(file_path) try: text = extract_text_from_pdf(file_path) extracted = CustomLLM()(text, mode='extract') return {"extracted_fields": extracted} except Exception as e: return JSONResponse( status_code=413, content={ "error": "Unable to process large document. Please try again with a PDF containing fewer pages." } ) @router.get("/final_summary/") async def get_final_summary(): if not version_summaries: return {"summary": "No version comparisons uploaded yet."} versioned = [ f"Changes from {v1} to {v2}:\n{summary}" for (v1, v2), summary in zip(version_pairs, version_summaries) ] combined_text = "\n\n".join(versioned) final_summary = CustomLLM()(combined_text) return { "pairwise_summaries": versioned, "final_summary": final_summary } @router.post("/reset/") async def reset_summary(): cleanup_old_files() version_pairs.clear() version_summaries.clear() return {"status": "Reset complete"} app.include_router(router, prefix="/doc", tags=["document_summarization"]) if __name__ == "__main__": uvicorn.run(app, host="127.0.0.1",port = 8726) <<utils.py>> from langchain_community.document_loaders import PyPDFLoader from langchain.text_splitter import RecursiveCharacterTextSplitter from langchain_core.documents import Document from difflib import SequenceMatcher def extract_text_from_pdf(pdf_path: str) -> str: loader = PyPDFLoader(pdf_path) pages = loader.load() text = "\n".join([doc.page_content for doc in pages if doc.page_content and len(doc.page_content.strip()) > 50]) return text.strip() def load_and_chunk_pdf(pdf_path,chunk_size = 12000,chunk_overlap = 2000): loader = PyPDFLoader(pdf_path) pages = loader.load() splitter = RecursiveCharacterTextSplitter( chunk_size = chunk_size, chunk_overlap = chunk_overlap, separators = ['\n\n','\n','.',' ',''] ) chunks = splitter.split_documents(pages) return chunks def get_diff_context(text1: str, text2: str) -> str: matcher = SequenceMatcher(None, text1.splitlines(), text2.splitlines()) diffs = [] for tag, i1, i2, j1, j2 in matcher.get_opcodes(): if tag == "replace": diffs.append(f"modified:\n{' '.join(text1.splitlines()[i1:i2])}\n -> \n{' '.join(text2.splitlines()[j1:j2])}") elif tag == "delete": diffs.append(f"Removed:\n{' '.join(text1.splitlines()[i1:i2])}\n") elif tag == "insert": diffs.append(f"Addedd:\n{' '.join(text2.splitlines()[j1:j2])}\n") print(f"diff :{diffs}") return "\n".join(diffs) if diffs else "No significant differences found." <<sm_chain.py>> from langchain.llms.base import LLM from langchain_community.document_loaders import PyPDFLoader from fastapi import FastAPI, File, UploadFile import uvicorn import requests import time app = FastAPI() class CustomLLM(LLM): def _call(self,content:str, mode: str = "summarize", **kwargs): if mode == "summarize": if mode == "summarize": role_prompt = ( """ You are a legal assistant. Read this legal document and provide a brief summary in exactly 150-200 words. Focus only on the most essential facts: Write in simple paragraph form without bullet points or lists. Keep it concise - do not exceed 200 words under any circumstances. Do not include any markdown formatting or special characters. """ ) question = "Summarize the provided document in exactly 150-200 words" elif mode == "extract": role_prompt = ( """ You are a legal document intelligence agent. Your task is to extract specific metadata from the provided legal agreement and return it in valid JSON format. Only use information explicitly present in the document — do not infer or hallucinate. Extract the following fields: { "title": "", "effective_date": "", "expiry_date": "", "party_name": "", "contract_type": "", "parties": [], "duration": "", "key_terms_and_conditions": "", "financial": { "payment_terms": "" }, "legal": { "liability_cap": "" }, "performance": { "service_level_agreement": "" } } Guidelines: - Dates must be in "YYYY-MM-DD" format. - Return an empty string ("") if a field is not found. - Do not include explanations or formatting instructions. - Return only the JSON — no surrounding commentary or headers. """ ) question = "Extract all fields in valid JSON format from the legal document as specified." elif mode == "difference": role_prompt = ( """ You are a legal assistant. You will be provided with a comparison between two versions of a legal document. Analyze the differences and provide a clear summary in exactly between 150-200 words. Focus on the most significant changes: key terms modified, major additions, or important removals. Write in simple paragraph form without bullet points or lists. your response between 150 and 200 words - no fewer or no more. Do not include any markdown formatting or special characters. """ ) question = "summarize the document changes exactly in 150-200 words" payload = { 'role': role_prompt, 'content': content, 'question': question, 'max_token': 1024, 'temperature': 0.1 } for attempt in range(3): try: res = requests.post('http://10ce', params=payload,timeout = 60) res.raise_for_status() return res.json().get('result','').strip() except Exception as e: print(f'[retry {attempt+1}] LLaMA call failed :{e}') time.sleep(2) <<now i want to build the vector database faiss in order to extract the fiels using vectordb in order to avoid the failing of larger files>> raise Exception("Failed to get response from LLaMA after 3 attempts") @property def _llm_type(self) : return 'custom-llama'
